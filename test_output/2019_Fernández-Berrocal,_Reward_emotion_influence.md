---
title: Reward and emotion influence attentional bias in rapid serial visual presentation
authors:
- María J Gutiérrez-Cobo, David Luque, Steven B Most, Pablo Fernández-Berrocal,
- Mike E Le Pelley
year: '2019'
journal: Quarterly Journal of Experimental Psychology 2019.72:2155-2167
doi: 10.1177/1747021819840615
tags:
- academic
- attentional-blink
- emotion
- emotion-induced-blindness
- faces
- japanese
- research-paper
- reward
- year-2019
created: '2025-07-19'
pdf-path: '[[Gutiérrez-Cobo et al. 2019 - Reward and emotion influence attentional
  bias in rapid serial visual presentation.pdf]]'
abstract-by: gemini-2.0-flash-001
language: ja
page-count: 13
file-size-mb: 0.48
---

# Reward and emotion influence attentional bias in rapid serial visual presentation

## 🧪 各実験の詳細

### 実験 1
**目的と仮説**: * この実験では、顔の感情（怒りまたは中立）が注意を捉えるかどうか、そして報酬の存在がその効果に影響を与えるかどうかを検証する。 * **実験手法**
**実験参加者**: UNSWシドニーの学生50名（平均年齢19.1歳、女性34名）が参加。 はRSVP（Rapid Serial Visual Presentation：高速逐次視覚提示）タスクを行い、一連の画像の中に埋め込まれた回転したターゲット画像（風景または建築物の写真）の回転方向（左または右）を識別する。ターゲットの直前に、怒り顔または中立顔のいずれかの顔画像がdistractor（妨害刺激）として提示される。 は、回転したターゲット画像の回転方向を矢印キーで回答する。報酬条件として、特定の顔（怒り顔または中立顔）がdistractorとして提示された場合、正解すると50ポイント獲得、不正解だと50ポイント失う。もう一方の顔がdistractorとして提示された場合は、正誤に関わらずポイントは変動しない。Distractorは、画像系列の3番目、4番目、5番目、または6番目の位置にランダムに配置され、ターゲットはdistractorの2つ後（Lag 2：200ms後）または4つ後（Lag 4：400ms後）に提示される。
**課題と刺激**: 参加者はRSVP（Rapid Serial Visual Presentation：高速逐次視覚提示）タスクを行い、一連の画像の中に埋め込まれた回転したターゲット画像（風景または建築物の写真）の回転方向（左または右）を識別する。ターゲットの直前に、怒り顔または中立顔のいずれかの顔画像がdistractor（妨害刺激）として提示される。
**手続き**: 各試行において、18枚の画像が100ms間隔で連続して提示される。参加者は、回転したターゲット画像の回転方向を矢印キーで回答する。報酬条件として、特定の顔（怒り顔または中立顔）がdistractorとして提示された場合、正解すると50ポイント獲得、不正解だと50ポイント失う。もう一方の顔がdistractorとして提示された場合は、正誤に関わらずポイントは変動しない。Distractorは、画像系列の3番目、4番目、5番目、または6番目の位置にランダムに配置され、ターゲットはdistractorの2つ後（Lag 2：200ms後）または4つ後（Lag 4：400ms後）に提示される。
**分析方法**: 2（顔の感情：怒り vs. 中立）× 2（グループ：怒り顔報酬 vs. 中立顔報酬）× 2（遅延：Lag 2 vs. Lag 4）のANOVA（Analysis of Variance：分散分析）を実施。必要に応じて、単純効果の分析や一元配置分散分析も実施。
**結果と小括**: * Lag 2では、怒り顔の後にターゲットの正答率が低下した。また、報酬が与えられる条件（valued trials）では、正答率が有意に低下した。Lag 4では、有意な効果は認められなかった。 * 顔の感情と報酬の両方が、ターゲットの識別精度に影響を与えることが示唆された。報酬が利用可能であることを示すdistractorの後に精度が低下することは、注意が報酬関連のdistractorに引きつけられることを示唆している。

### 実験 1
**実験参加者**: が戦略的に感情を識別しようとした可能性を排除するため、顔の感情とは無関係に報酬を操作する。顔の性別が報酬に関連付けられている場合でも、顔の感情が注意に影響を与えるかどうかを検証する。 * **実験手法** UNSWシドニーの学生50名（平均年齢19.3歳、女性31名）が参加。

### 実験 1
**実験参加者**: には男性の顔が報酬あり、残りの半数には女性の顔が報酬ありと設定。顔の感情（怒りまたは中立）は、報酬とは無関係。LagはLag 2のみとし、baseline trialsは省略。
**課題と刺激**: 実験1と同様のRSVPタスクを使用。
**手続き**: 顔の性別（男性または女性）によって報酬の有無が決定されるように変更。半数の参加者には男性の顔が報酬あり、残りの半数には女性の顔が報酬ありと設定。顔の感情（怒りまたは中立）は、報酬とは無関係。LagはLag 2のみとし、baseline trialsは省略。
**分析方法**: 2（顔の感情：怒り vs. 中立）× 2（報酬：報酬あり vs. 報酬なし）の反復測定ANOVAを実施。さらに、JASPを用いてベイズ分析（Bayesian analysis）を実施し、モデルの比較を行った。事前分布にはデフォルトのコーシー分布（Cauchy prior）を使用。
**結果と小括**: * 怒り顔の後にターゲットの正答率が低下した。また、報酬が与えられる条件でも、正答率が有意に低下した。感情と報酬の間に有意な交互作用が認められた。 、感情と報酬の主効果のみを持つモデルが最も支持された。

### 実験 1
**実験参加者**: スペインの大学生49名（平均年齢22.59歳、女性41名）が参加。
**結果と小括**: を統合し、顔の感情と報酬の効果、および両者の交互作用についてさらに解明を試みる。実験2と同様に顔の性別で報酬を操作しつつ、実験1と同様にLag 2とLag 4、baseline trialsを設ける。 * **実験手法**

### 実験 1
**課題と刺激**: 実験1および2と同様のRSVPタスクを使用。

### 実験 2
**手続き**: 実験2と同様に、顔の性別によって報酬の有無が決定される。実験1と同様に、Lag 2とLag 4、baseline trialsを設ける。
**分析方法**: 2（顔の感情：怒り vs. 中立）× 2（報酬：報酬あり vs. 報酬なし）の反復測定ANOVAを実施。さらに、ベイズ分析を実施。
**結果と小括**: * Lag 2では、怒り顔の後にターゲットの正答率が低下した。また、報酬が与えられる条件でも、正答率が有意に低下した。感情と報酬の間に有意な交互作用は認められなかった。

### 実験 1
**結果と小括**: 、感情と報酬の主効果のみを持つモデルが最も支持された。

## 💡 総合考察と結論

. 総合考察と結論 (General Discussion) 結果の統合: 3つの実験を通して、顔の感情（特に怒り顔）は、たとえタスクと無関係であっても、注意を引くことが示された。また、報酬に関連付けられた顔も注意を引きやすいことが示された。 結論: 感情的な顔は、タスクと無関係であってもEIBを引き起こす可能性があり、顔の感情の処理には、少なくとも部分的には自動的なプロセスが関与している可能性が示唆された。 学術的貢献: 本研究は、顔の感情が注意に与える影響を、報酬との関連性に着目して詳細に検討した点に新規性がある。特に、タスクと無関係な顔の感情が注意を引くことを示した点は、感情と注意に関する既存の研究に新たな視点を提供する。 研究の限界と今後の展望: 本研究では、感情刺激として怒り顔のみを使用しているため、感情価（valence）または喚起度（arousal）のどちらが注意を引く要因であるかを区別できない。今後は、怒り顔と幸福顔など、喚起度が同程度で感情価が異なる刺激を用いて検討する必要がある。また、顔の感情が注意に与える影響には、個人の不安傾向などの個人差が影響する可能性があり、今後の研究で検討すべき課題である。

## 📈 図表

- **Figure 1**: a). Participants were informed that on each trial, they (p.4)
- **Figure 1**: (a) Schematic of a trial from the Rapid Serial Visual Presentation (RSVP) task—actual RSVP streams comprised 18 (p.5)
- **Figure 1**: b and c shows mean accuracy of (p.6)
- **Figure 1**: d shows mean accuracy of participants’ responses (p.7)
- **Figure 2**: a and b shows mean accuracy of responses to the (p.8)
- **Figure 2**: Accuracy of responses to the target in Experiment (p.9)
- **Table 1**: summarises key statistical find- (p.9)
- **Table 1**: ) of an interaction between (p.10)
- **Table 1**: Summary of statistical findings across Experiments 1 (p.10)

## 🔗 関連ノート

*[app-obsidian_ai_organizerで自動追加]*

## 📚 参考文献（抜粋）

1. 91.7% (0.7%) for trials with a face distractor and 95.3% (0.5%) for baseline trials, t(49) = 4.13, p < .001, dz = 0.58. At Lag 4, the difference was numerically smaller—92.3% (0.6%) for trials with a distractor ver- sus 94.2% (0.5%) for baseline trials—but still signifi- cant, t(49) = 3.19, p = .003, dz = 0.45. These findings indicate that performance in the RSVP task was gener- ally impaired when the target was preceded by a distrac- tor image belonging to a category (faces) that was different from all other images in the stream (architec- tural/landscape images) than when it did not. Of more interest for current purposes is how the impairment in accuracy produced by the face distractor varied as a function of the emotion and value-association of that face (recall that for half of participants, angry faces were valued and neutral faces were non-valued; for the other half of participants, this was reversed). These data were initially analysed using a 2 (face emotion: angry vs. neutral) × 2 (group: angry face rewarded vs. neutral face rewarded) × 2 (lag: Lag 2 vs. Lag 4) analysis of variance (ANOVA). This revealed (among other find- ings) a significant emotion × group × lag interaction, F(1, 48) = 4.85, p < .05, ηp 2  = .09. Consequently, to pro- vide more detailed analysis, we ran separate 2 (emo- tion) × 2 (group) ANOVAs for each distractor–target lag. At Lag 2, this analysis revealed a significant main effect of emotion, F(1, 48) = 6.57, p = .014, ηp 2  = .12; overall, accuracy was lower following an angry distractor face than a neutral face. The main effect of group was not sig- nificant, F(1, 48) = 1.17, p = .29, ηp 2  = .02. However, the effect of group interacted with emotion, F(1, 48) = 19.3, p < .001, ηp 2  = .29. Analysis of simple effects revealed that the effect of emotion was significant in the group of participants for whom angry faces were valued and neu- tral faces were non-valued, F(1, 24) = 22.5, p < .001, ηp 2  = .48. The effect of emotion was not significant in the group for whom neutral faces were valued and angry faces were non-valued, F(1, 48) = 1.81, p = .19, ηp 2  = .07. Finally, a one-way ANOVA was used to examine the effect of reward, by comparing accuracy on valued trials with accuracy on non-valued trials, regardless of the emotion of the distractor face. This analysis revealed a significant effect of reward at Lag 2, F(1, 49) = 17.31, p < .001, ηp 2  = .26. At Lag 4, the emotion × group ANOVA found no signifi- cant main effect of emotion, F(1, 48) = 0.37, p = .54, ηp 2  = .01, or group, F(1, 48) = 2.54, p = .12, ηp 2  = .05, and no interac- tion between these factors, F(1, 48) = 1.28, p = .26, ηp 2  = .03. A one-way ANOVA examining the influence of reward independent of emotion (across all participants) found no significant effect, F(1, 49) = 1.30, p = .26, ηp 2  = .026. Discussion When there was a short distractor–target lag (200 ms), accuracy of participants’ responses to the target depended on both the emotion of the distractor face, and whether or not it signalled the availability of reward. In terms of reward, accuracy was significantly impaired following a distractor that signalled the availability of reward, com- pared with a distractor signalling that no reward was avail- able. This is counterproductive, because it means that accuracy was lower on trials that influenced participants’ final monetary payment than on trials that “didn’t matter,” that is, trials on which the response could have no effect on payment. This maladaptive influence of reward-signalling converges with a body of recent data showing greater attention to reward-related distractors even when this results in a reduced payoff (e.g., Le Pelley, Pearson, Griffiths, & Beesley, 2015; Le Pelley et  al., 2017; Le Pelley et al., 2018). Experiment 1 represents the first time that this pattern has been shown using faces as the reward- signalling distractors. Returning to a point raised in the Introduction, this find- ing is important, because it indicates that the emotions in the pictures of faces used here were sufficiently discrimi- nable to support different patterns of rapid attentional bias (as it was the emotion of the face [angry/neutral] that defined whether or not it signalled reward). On this issue, it is notable that we also observed an effect of the emotion of the distractor face on response accuracy, over and above the effect of reward-signalling. Across all participants, accuracy was lower in trials with angry distractor faces compared with neutral faces. That is, the emotion of the face influenced the extent to which it held attention. This effect of emotion interacted with the effect of reward-sig- nalling, such that the angry-versus-neutral difference was more pronounced in non-valued trials than valued trials. We postpone further discussion of this interaction to the “Discussion” section of Experiment 2. The influences of emotion and reward on attention in Experiment 1 were rapid and short-lived, in that no signifi- cant effects were found with a distractor–target lag of 400 ms. The timescale of the effects observed in Experiment 1 is characteristic of the attentional blink and related effects (e.g., Cobos, Gutiérrez-Cobo, Morís, & Luque, 2017; Le Pelley et al., 2017; Raymond et al., 1992; Stein et al., 2009), which tends to peak at a lag of around 200 ms before dissipating rapidly. Notably, in Experiment 1, participants were not required to identify the faces to perform correctly. Their task was to identify the orientation of the rotated picture; participants were explicitly informed that the rotated picture would never be a face, and that they would maximise their payoff in the task by ignoring the faces entirely. The use of a (colour)
2. 34.7 in favour of this model over the null. Notably, the “main effects only” model was also favoured over a model that also included the interaction, BF01 = 1.41, although the strength of support for one model over the other here is only at an “anecdotal” level (Jeffreys, 1961). Discussion The main findings of Experiment 2 are broadly similar to those of Experiment 1. Specifically, the accuracy of par- ticipants’ responses to the rotated target depended both on whether or not the distractor face signalled reward and on its emotion. This latter effect is critical because it demon- strates an effect of emotion on the attentional prioritisation of faces even though this emotion was entirely task-irrele- vant (in contrast to Experiment 3 of Stein et al., 2009).
3. 3. The contrast with Experiment 2 is notable here, as both Experiments 2 and 3 used a very similar design, in which facial emotion was entirely task-irrelevant. That said, the “discrepancy” between the findings of these latter experi- ments may be more apparent than real: Bayesian analyses suggested that neither Experiment 2 nor Experiment 3 pro- vided strong evidence for the presence of an emo- tion × reward interaction. We return to this issue in the “General Discussion.” For the time being, we merely high- light the key finding that was replicated once again in Experiment 3: Lag 2 response accuracy is influenced by both facial emotion and reward. For ease of comparison across experiments, Table 1 summarises key statistical find- ings for the Lag 2 data in Experiments 1 to 3. General discussion Facial emotion constitutes an important source of informa- tion, for example, as a signal of threat, safety, friendship, and so on. Rapid and efficient processing of facial emotion may thus bring adaptive advantages. However, previous evidence suggests that faces may not be automatically pri- oritised for attentional processing. Specifically, Stein et al. (2009, see also Van Dam, Earleywine, & Altarriba, 2012) showed that emotional faces produced an impairment in recognition of a subsequent target (known as emotion- induced blindness, EIB) only when participants were required to respond to the faces’ emotion to complete the task. In contrast, other classes of emotional stimuli have been shown to produce EIB even when participants are not required to make any response to them (Kennedy & Most, 2015b; Most et al., 2007). In the current experiments, we examined further whether emotional faces can produce EIB when partici- pants are not required to identify or respond to these faces. We did this by combining the manipulation of emotion with a manipulation of reward. Faces only ever appeared as distractors, shortly before the presentation of a rotated target picture. Certain faces indicated that correct/incorrect responses to the target would be rewarded/punished, whereas other faces indicated that responses would be inconsequential. Thus, even though the faces carried infor- mation about the availability of reward, they were not the targets that participants were required to identify and Figure 2.  Accuracy of responses to the target in Experiment 3 for Lag 2 trials (a) and Lag 4 trials (b), where lag refers to the difference in serial position of the distractor face and target in the RSVP stream (or between the filler item that substituted for the distractor and the target on baseline trials). The dotted line and shaded region show mean ± SEM accuracy on baseline trials, averaged across all participants. Error bars show SEM.
4. 1. This is in contrast to some other studies of emotion-induced blindness that have used semantically defined targets, for example, a task in which all stimuli in the RSVP stream are words, and participants are required to detect a job-related or colour-related word (the target), which can be preceded by an emotion-related distractor word (e.g., Arnell, Killman, & Fijavz, 2007; Barnard, Ramponi, Battye, Mackintosh, & Barnard, 2005). Under these conditions, participants need to
5. 3017. doi:10.1523/JNEUROSCI.3205-16.2017

*... and 4 more references*

## 📝 個人的なメモ

- [ ] 詳細を読む
- [ ] 実装を試す
- [ ] 関連研究を調査